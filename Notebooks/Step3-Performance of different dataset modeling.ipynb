{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calculate sensitivity, specificity, accuracy, MCC, and AUC of these three Models.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Here we need to use the files in the three folders (i.e. \"Model 1 prediction results\", \"Model 2 prediction results\", and \"Model 3 prediction results\") and this script corresponds to \"Table 2\" in our manuscript.</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, sys\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the training set in Model 1.</h4>\n",
    "\n",
    "<h4>Notice: the best cutoff of training set in Model 1 is 0.231.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the training set in Model 1:\n",
      "sensitivity is 0.91\n",
      "specificity is 0.96\n",
      "accuracy is 0.95\n",
      "MCC is 0.81\n",
      "AUC is 0.98\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 1 prediction results/training_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.231:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.231:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity1 = TP/(TP+FN)\n",
    "specificity1 = TN/(TN+FP)\n",
    "accuracy1 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC1 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC1 = auc(fpr1,tpr1)\n",
    "print(\"The prediction result of the training set in Model 1:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity1,\"\\n\",specificity1,\"\\n\",accuracy1,\"\\n\",MCC1,\"\\n\",AUC1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Then, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the test set in Model 1.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the validation set in Model 1:\n",
      "sensitivity is 0.94\n",
      "specificity is 0.96\n",
      "accuracy is 0.95\n",
      "MCC is 0.81\n",
      "AUC is 0.99\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 1 prediction results/test_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.231:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.231:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity2 = TP/(TP+FN)\n",
    "specificity2 = TN/(TN+FP)\n",
    "accuracy2 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC2 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC2 = auc(fpr2,tpr2)\n",
    "print(\"The prediction result of the validation set in Model 1:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity2,\"\\n\",specificity2,\"\\n\",accuracy2,\"\\n\",MCC2,\"\\n\",AUC2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>And we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the GWASdb and 1KGP datasets in Model 1.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the GWASdb and 1KGP datasets in Model 1:\n",
      "sensitivity is 0.34\n",
      "specificity is 0.80\n",
      "accuracy is 0.66\n",
      "MCC is 0.15\n",
      "AUC is 0.60\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 1 prediction results/GWASdb_1kgp_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.231:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.231:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity3 = TP/(TP+FN)\n",
    "specificity3 = TN/(TN+FP)\n",
    "accuracy3 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC3 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr3, tpr3, thresholds3 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC3 = auc(fpr3,tpr3)\n",
    "print(\"The prediction result of the GWASdb and 1KGP datasets in Model 1:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity3,\"\\n\",specificity3,\"\\n\",accuracy3,\"\\n\",MCC3,\"\\n\",AUC3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Second, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the training set in Model 2.</h4>\n",
    "\n",
    "<h4>Notice: the best cutoff of training set in Model 2 is 0.301.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the training set in Model 2:\n",
      "sensitivity is 0.75\n",
      "specificity is 0.58\n",
      "accuracy is 0.63\n",
      "MCC is 0.30\n",
      "AUC is 0.72\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 2 prediction results/training_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.301:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.301:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity4 = TP/(TP+FN)\n",
    "specificity4 = TN/(TN+FP)\n",
    "accuracy4 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC4 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr4, tpr4, thresholds4 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC4 = auc(fpr4,tpr4)\n",
    "print(\"The prediction result of the training set in Model 2:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity4,\"\\n\",specificity4,\"\\n\",accuracy4,\"\\n\",MCC4,\"\\n\",AUC4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Then, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the test set in Model 2.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the validation set in Model 2:\n",
      "sensitivity is 0.71\n",
      "specificity is 0.57\n",
      "accuracy is 0.61\n",
      "MCC is 0.25\n",
      "AUC is 0.70\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 2 prediction results/test_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.301:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.301:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity5 = TP/(TP+FN)\n",
    "specificity5 = TN/(TN+FP)\n",
    "accuracy5 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC5 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr5, tpr5, thresholds5 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC5 = auc(fpr5,tpr5)\n",
    "print(\"The prediction result of the validation set in Model 2:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity5,\"\\n\",specificity5,\"\\n\",accuracy5,\"\\n\",MCC5,\"\\n\",AUC5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>And we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the ClinVar dataset in Model 2.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the ClinVar dataset in Model 2:\n",
      "sensitivity is 0.90\n",
      "specificity is 0.18\n",
      "accuracy is 0.27\n",
      "MCC is 0.07\n",
      "AUC is 0.58\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 2 prediction results/clinvar_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.301:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.301:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity6 = TP/(TP+FN)\n",
    "specificity6 = TN/(TN+FP)\n",
    "accuracy6 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC6 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr6, tpr6, thresholds6 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC6 = auc(fpr6,tpr6)\n",
    "print(\"The prediction result of the ClinVar dataset in Model 2:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.2f\"%(\"\\n\",sensitivity6,\"\\n\",specificity6,\"\\n\",accuracy6,\"\\n\",MCC6,\"\\n\",AUC6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Third, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the training set in Model 3.</h4>\n",
    "\n",
    "<h4>Notice: the best cutoff of training set in Model 3 is 0.256.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the training set in Mode3 3:\n",
      "sensitivity is 0.77\n",
      "specificity is 0.72\n",
      "accuracy is 0.74\n",
      "MCC is 0.43\n",
      "AUC is 0.8\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 3 prediction results/training_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.256:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.256:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity7 = TP/(TP+FN)\n",
    "specificity7 = TN/(TN+FP)\n",
    "accuracy7 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC7 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr7, tpr7, thresholds7 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC7 = auc(fpr7,tpr7)\n",
    "print(\"The prediction result of the training set in Mode3 3:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.1f\"%(\"\\n\",sensitivity7,\"\\n\",specificity7,\"\\n\",accuracy7,\"\\n\",MCC7,\"\\n\",AUC7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Then, we calculated the sensitivity, specificity, accuracy, MCC, and AUC of the test set in Model 3.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of the validation set in Model 3:\n",
      "sensitivity is 0.78\n",
      "specificity is 0.74\n",
      "accuracy is 0.75\n",
      "MCC is 0.44\n",
      "AUC is 0.8\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "truelabellist = []\n",
    "predlabellist = []\n",
    "predscorelist = []\n",
    "f = open(\"../Model 3 prediction results/test_predictproba\",'rt')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    li = re.split(\"\\t\",line)\n",
    "    True_label = int(li[0])\n",
    "    truelabellist.append(True_label)\n",
    "    Pred_score = float(li[-1])\n",
    "    predscorelist.append(Pred_score)\n",
    "    if True_label == 1:\n",
    "        if Pred_score >= 0.256:\n",
    "            TP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            FN += 1\n",
    "            predlabellist.append(0)\n",
    "    else:\n",
    "        if Pred_score >= 0.256:\n",
    "            FP += 1\n",
    "            predlabellist.append(1)\n",
    "        else:\n",
    "            TN += 1\n",
    "            predlabellist.append(0)\n",
    "sensitivity8 = TP/(TP+FN)\n",
    "specificity8 = TN/(TN+FP)\n",
    "accuracy8 = (TP+TN)/(TP+TN+FP+FN)\n",
    "MCC8 = matthews_corrcoef(truelabellist,predlabellist)\n",
    "fpr8, tpr8, thresholds8 = metrics.roc_curve(np.array(truelabellist),np.array(predscorelist),pos_label=1)\n",
    "AUC8 = auc(fpr8,tpr8)\n",
    "print(\"The prediction result of the validation set in Model 3:%ssensitivity is %.2f%sspecificity is %.2f%saccuracy is %.2f%sMCC is %.2f%sAUC is %.1f\"%(\"\\n\",sensitivity8,\"\\n\",specificity8,\"\\n\",accuracy8,\"\\n\",MCC8,\"\\n\",AUC8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
